# 카프카 기능 구현


            스마트카 실시간 로그 에이전트의 싱크를 보면 카프카 싱크를 만들었다.
            카프카 싱크는 스마트카에서 발생되는 운전자의 실시간 로그 데이터를 받아서 카프카 싱크를 통해서 카프카로 전송하는 플럼의 에이전트다
            플럼의 카프카 싱크가 바라보고 있는 카프카를 기능 구현을 하였다.

![카프카producer_consumer](https://user-images.githubusercontent.com/76901290/126336288-adde1259-fc18-437a-afbf-407ea58e6f6e.jpg)


            먼저 Server02에 카프카를 설치했다. 그리고 카프카 안에 SmartCar-Topic이라는 토픽을 하나 만들어서 생성을 했다.
            카프카에는 데이터를 생성하는 Producer와 데이터를 소비하는 Consumer가 있다.
            Producer가 플럼의 실시간 로그 에이전트에서 전송했던 Kafka Sink이다. 
            스마트카에서 수집한 로그 데이터들을 플럼이 수집을 하고 Kafka Sink에서 카프카 Broker로 쏘면
            SmartCar-Topic이라는 곳에 저장이 되고 이 Topic을 바라보고 있는 Consumer, 이것을 단순하게
            Console상에서 Consumer을 작동을 시키면 Topic에 있는 데이터를 그대로 Consumer들이 수신해서 뿌려준다.
            'Hello! BigData!'를 Producer가 전송을 하면 Consumer들을 똑같이 'Hello! BigData!'를 브로드캐스팅 받는다.
            Consumer1에도 'Hello! BigData!'가 출력되고 Consumer2에도 'Hello! BigData!'가 Kafka Broker에 있는 SmartCar-Topic을 통해 수신받게 된다.


- 카프카 Topic 생성

            
            $ kafka-topics --create -- zookeeper server02.hadoop.com:2181 -- replication-factor 1 -- partitions 1 --topic SmartCar-Topic
            
            kafka를 사용하기 위해 먼저 kafka 안에 topic을 만든다.
            zookeeper 서버를 지정해 주고 replication-factor도 지정해준다 broker가 1개밖에 없으므로 1로 지정하고
            partition이라고 해서 전송한 메세지를 여러개의 broker에 나눠서 분리 저장할건지를 물어보는건데 broker가 하나밖에 없으므로 1로 세팅한다.
            그리고 topic명을 SmartCar-Topic으로 한다.


- 카프카 Producer 사용

            
            $ kafka-console-producer -- broker-list server02.hadoop.com:9092 - topic SmartCar-Topic
            
            카프카 콘솔에 프로듀서를 사용하는 명령이다. 카프카에 있는 브로커 서버를 지정해주고 앞에 만들었던 topic 명을 지정해준다.
            그러면 이 프로듀서는 앞에서 만들었던 브로커에 토픽을 바라보고 있는 메세지 생산자가 되는 것이다.


- 카프카 Consumer-1 사용

            
            $ kafka-console-consumer --bootstrap-server server02.hadoop.com:9092 --topic SmartCar-Topic --partition 0 --from-beginning
            
            Producer가 어떠한 메시지를 생산하면 Consumer들은 이 메세지를 받아야한다.
            bootstrap-server를 지정해주고 같은 topic을 바라봐야하므로 SmartCar-Topic을 지정해준다.
            partition은 Consumer에서 없어도 되므르 0, from-beginning은 해당 topic에 있는 데이터를 지금까지 받지 못한 데이터가 있으면 처음부터 끝까지 받아서 출력하라는 뜻이다.
            이 명령어를 수행하면 Producer가 생성했던 메세지가 그대로 수신된다.

![Consumer1](https://user-images.githubusercontent.com/76901290/126336296-c6c6ff17-796a-4944-b384-8c152cdbf0c4.png)



- 카프카 Consumer-2 사용


            $ kafka-console-consumer --bootstrap-server server02.hadoop.com:9092 --topic SmartCar-Topic --partition 0 --from-beginning
            
            어떠한 메세지가 Consumer1과 Consumer2에서 동시에 수신한다.

![Consumer2](https://user-images.githubusercontent.com/76901290/126336310-846ee58f-6e53-4886-8247-0dae3346f42a.png)

[*인프런 교육과정:빅데이터 파일럿 프로젝트](https://www.inflearn.com/course/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%8C%8C%EC%9D%BC%EB%9F%BF-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/dashboard)
